Robotic Clay Sculpting using ACT (Action Chunking with Transformers)
-------

#### ACT Project Website: https://tonyzhaozh.github.io/aloha/

This repo contains an implementation of ACT for robotic clay sculpting.


### Repo Structure
- ``imitate_episodes.py`` Train and Evaluate ACT
- ``policy.py`` An adaptor for ACT policy
- ``detr`` Model definitions of ACT, modified from DETR
- ``sim_env.py`` Mujoco + DM_Control environments with joint space control
- ``ee_sim_env.py`` Mujoco + DM_Control environments with EE space control
- ``scripted_policy.py`` Scripted policies for sim environments
- ``constants.py`` Constants shared across files
- ``utils.py`` Utils such as data loading and helper functions
- ``visualize_episodes.py`` Save videos from a .hdf5 dataset


### Installation

    conda create -n sculpt-act python=3.9
    conda activate sculpt-act
    cd sculpt_act && pip install requirements.txt

### Training 

To train ACT:
    
    # Clay sculpting task
    python3 imitate_episodes.py \
    --task_name clay_sculpting \
    --ckpt_dir <ckpt dir> \
    --policy_class ACT --kl_weight 10 --chunk_size 100 --hidden_dim 512 --batch_size 8 --dim_feedforward 3200 \
    --num_epochs 2000  --lr 1e-5 \
    --seed 0

### Evaluation
To evaluate the policy, run the same command but add ``--eval``. This loads the best validation checkpoint.
To enable temporal ensembling, add flag ``--temporal_agg``.
Videos will be saved to ``<ckpt_dir>`` for each rollout.
You can also add ``--onscreen_render`` to see real-time rendering during evaluation.

